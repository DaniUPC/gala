#!/usr/bin/env python

# Python standard library
import sys, os, argparse, cPickle
import subprocess as sp
import logging

# external libraries
from numpy import unique, inf
from skimage import morphology as skmorph
from scipy.ndimage import label

# local modules
from ray import imio, agglo, morpho, classify

if __name__ == '__main__':
    MasterLogger = logging.getLogger('pipeline')
    MasterLogger.propagate = False
    MasterLogger.setLevel(logging.DEBUG)
    console = logging.StreamHandler(sys.stdout)
    console.setLevel(logging.INFO)
    
    formatter = logging.Formatter('%(levelname)-8s %(message)s')
    console.setFormatter(formatter)
    MasterLogger.addHandler(console)
    prim = logging.FileHandler("ray-segment.log", 'a')
    prim.setLevel(logging.DEBUG)
    prim.setFormatter(logging.Formatter(fmt='%(asctime)s %(levelname)-8s %(message)s', datefmt='%m-%d-%y %H:%M'))
    MasterLogger.addHandler(prim)

    MasterLogger.info("Script called: " + ' '.join(sys.argv))
    MasterLogger.info("Script run from: " + os.path.realpath('.'))

    parser = argparse.ArgumentParser(
        description='Train a classifier for agglomerative segmentation.')
    parser.add_argument('fin',
        help='The boundary probability map to be segmented, in HDF5 format ' +\
        '(group "stack" is assumed).')
    parser.add_argument('-I', '--remove-inclusions', action='store_true',
        default=False, 
        help='Remove inclusions before segmenting and before output.')
    parser.add_argument('-F', '--feature-manager', metavar='EVAL_STR',
        default='classify.CompositeFeatureManager(children=' +\
            '[classify.MomentsFeatureManager(), ' +\
            'classify.HistogramFeatureManager(25, 0, 1, [0.1, 0.5, 0.9])]' +\
            ')',
        help='Specify the feature manager you would like to use. ' +\
        '(This HAS to match the one used during training!)')
    parser.add_argument('-k', '--classifier', metavar='CL_FILE',
        help='Use the agglomeration classifier from file CL_FILE.')
    parser.add_argument('-T', '--training-data', metavar='TR_FILE',
        type=classify.load_training_data_from_disk,
        help='Use the agglomeration training data in TR_FILE.')
    parser.add_argument('-V', '--expected-vi', action='store_true', 
        default=False,
        help='Use expected change in VI as agglomeration function.')
    parser.add_argument('-f', '--priority-function', metavar='EVAL_STR',
        default='agglo.boundary_median',
        help='Use specified priority function (when not using a classifier).')
    parser.add_argument('-N', '--num-training', metavar='UINT', type=int,
        help='Specify the number of training examples to sample.')
    parser.add_argument('-t', '--thresholds', nargs='+', default=[],
        metavar='FLOAT',
        help='Output segmentations for the specified thresholds.')
    parser.add_argument('-w', '--watershed', metavar='FILE',
        help='Load the watershed or other oversegmentation from FILE.')
    parser.add_argument('-P', '--show-progress', action='store_true', 
        default=False, help='Show a progress bar.')
    parser.add_argument('-Z', '--nozeros', action='store_false', 
        default=True, help='Disable nozeros mode.')
    parser.add_argument('-v', '--verbose', action='store_true', default=False,
        help='Print runtime information about execution.')
    parser.add_argument('-J', '--no-graph-json', action='store_true',
        help='When outputting to Raveler, don\'t bother outputting graph.')
    parser.add_argument('-i', '--images', nargs='+',
        help='specify the grayscale images for Raveler export.')
    parser.add_argument('--output_dir', type=str,
        help="Directory for all output", default='./', dest='output_dir')
    parser.add_argument('--experiment_name', type=str, 
        help="Name of the experiment -- will be used as the base name for all outputs",
        dest='experiment_name', required=True)
    args = parser.parse_args()

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)

    dname, fname = os.path.split(args.experiment_name)

    if dname != "":
        MasterLogger.error("Experiment name cannot be a path")
        sys.exit(1)    

    h5stacks = args.output_dir + "/segmentations"
    if not os.path.exists(h5stacks):
        os.makedirs(h5stacks)
    h5stacks = h5stacks + "/" + args.experiment_name + '-%0.2f'

    ravelervol = args.output_dir + "/raveler-exports"
    if not os.path.exists(ravelervol):
        os.makedirs(ravelervol)
    ravelervol = ravelervol + "/" + args.experiment_name + '-%0.2f'   


    # load all the required data
    p = imio.read_image_stack(args.fin)

    im = imio.read_image_stack(args.images) if args.images is not None else None
    if args.watershed is not None:
        ws = imio.read_image_stack(args.watershed)
    else:
        MasterLogger.info("Performing watershed")
        ws = skmorph.watershed(p, label(p==0)[0])
        MasterLogger.info("Finished performing watershed")
    fm = eval(args.feature_manager, {}, {'classify': classify})

    
    # Load training data or classifier
    if args.training_data is not None or args.classifier is not None:
        if args.classifier is not None:
            MasterLogger.info("Loading classifier")
            cl = classify.RandomForest()
            cl.load_from_disk(args.classifier)
        else:
            MasterLogger.info("Training classifier")
            cl = classify.RandomForest().fit(args.training_data[0], 
                args.training_data[1][:,0], args.num_training)
            MasterLogger.info("Finished training classifier")
        if args.expected_vi:
            mpf = agglo.expected_change_vi(fm, cl)
        else:
            mpf = agglo.classifier_probability(fm, cl)
    else:
        mpf = eval(args.priority_function, {}, {'agglo': agglo})

    MasterLogger.info("Building RAG")
    g = agglo.Rag(ws, p, mpf, feature_manager=fm, 
                  show_progress=args.show_progress, nozeros=args.nozeros)
    MasterLogger.info("Finished building RAG")
    if args.remove_inclusions:
        MasterLogger.info("Removing inclusions with " + str(g.number_of_nodes()) + " nodes")
        g.remove_inclusions()
        MasterLogger.info("Finished removing inclusions with " + str(g.number_of_nodes()) + " nodes")
        ws = g.get_segmentation()
    sps = imio.raveler_serial_section_map(ws, 0, False, False)
    for t in map(float, args.thresholds):
        MasterLogger.info("Agglomerating RAG to " + str(t) + " with " + str(g.number_of_nodes()) + " nodes")
        g.agglomerate(t)
        MasterLogger.info("Finished agglomerating RAG to " + str(t) + " with " + str(g.number_of_nodes()) + " nodes")
        MasterLogger.info("Removing inclusions" + " with " + str(g.number_of_nodes()) + " nodes")
        g.remove_inclusions()
        MasterLogger.info("Finished removing inclusions" + " with " + str(g.number_of_nodes()) + " nodes")
        s = g.get_segmentation()
        MasterLogger.info("Exporting volume")
        imio.write_image_stack(s, (h5stacks +'.lzf.h5')%t, compression='lzf')
        g.rebuild_merge_queue()
        imio.raveler_output_shortcut(ws, s, im, (ravelervol)%t, sps)
        if not args.no_graph_json:
            g.write_plaza_json(
                os.path.join((ravelervol)%t, 'graph.json'))
    MasterLogger.info("Complete RAG agglomeration")
    g.agglomerate(inf)
    MasterLogger.info("Finished complete RAG agglomeration")
    u = g.get_ucm()
    MasterLogger.info("Writing final ucm")
    imio.write_image_stack(u, (h5stacks + '.ucm.lzf.h5')%inf, compression='lzf')
