#!/usr/bin/env python

from ray import *
import sys
import os
from skimage import morphology as skmorph
from scipy.ndimage import label
import argparse
import json
import h5py
import numpy

format_help = """\
            Initial configuration json file needed.  For example:
            {
                "generate_boundary_prediction" : true,
                "generate_raveler_instance" : true,
                "perform_median_segmentation" : false,
                "perform_inclusion_removal" : false,
                "use_ilp_prediction" : false,
                "segmentation_thresholds" : [ 0, 0.1 ],
                "output_dir" : "./",
                "ilpfile" : "<ilastik ilp>",
                "stack_path" : "<file_path/*.png>",
                "stack_name" : "<some identifier>",
                "version" : "1",
                "features" : {
                    "Color" : ["small", "medium"],
                    "Texture" : ["large", "gigahuge"],
                    "Orientation" : ["gigahuge"],
                    "Edge": ["small"]
                }
            }"""

feature_hash = {}
feature_hash["tiny"] = 0.1
feature_hash["small"] = 0.3
feature_hash["medium"] = 0.7
feature_hash["large"] = 1.0
feature_hash["huge"] = 3.0
feature_hash["megahuge"] = 5.0
feature_hash["gigahuge"] = 10.0

def main(argv):
    parser = argparse.ArgumentParser(description="Segmentation pipeline (currently featuring boundary prediction and median agglomeration")
    parser.add_argument('--initfile', type=str, help=format_help, dest='initfile', required=True)
    args = parser.parse_args()

    json_file = open(args.initfile)
    json_val = json.load(json_file)
    json_file.close()

    image_stack = imio.read_image_stack(json_val["stack_path"])

    stackname = json_val["output_dir"] + "/" + json_val["stack_name"]
    stackname = stackname + "-v" + json_val["version"]
    if json_val["generate_boundary_prediction"] and not json_val["use_ilp_prediction"]:
        imio.write_ilastik_batch_volume(image_stack, str(stackname + ".h5"))
        #write temp.json
        json_val_out = {}
        json_val_out["output_dir"] = json_val["output_dir"]
        json_val_out["session"] = json_val["ilpfile"]
        json_val_out["images"] = []
        image_array = json_val_out["images"]
        image_array.append( { "name" : str(stackname + ".h5") } )
        json_val_out["features"] = []

        features = json_val["features"]
        for feat in iter(features):
            for featsize in features[feat]:
                json_val_out["features"].append([feat, feature_hash[featsize] ])
        json_file_out = open("temp.json", "w")
        json_file_out.write(json.dumps(json_val_out, indent=4))
        json_file_out.close()

        os.system('ilastik_batch --config_file=temp.json')
        os.system('rm -f temp.json')
    elif json_val["use_ilp_prediction"]:
        os.system("rm -f " + str(stackname + ".h5_processed.h5"))
        imio.write_ilastik_batch_volume(image_stack, str(stackname + ".h5_processed.h5"))
        image_stack = image_stack.transpose((0, 2, 1))
        f1 = h5py.File(str(stackname + ".h5_processed.h5"), 'a')
        f2 = h5py.File(json_val["ilpfile"], 'r')
        f1.copy(f2['/DataSets/dataItem00/prediction'], 'volume/prediction')
        f1.close()
        f2.close()

    if json_val["generate_raveler_instance"]:
        prediction = imio.read_image_stack(str(stackname + ".h5_processed.h5"), group='/volume/prediction')
        prediction0 = prediction[...,0]

        if json_val["use_ilp_prediction"]:
            prediction0 = prediction0.transpose((2, 1, 0))
        seeds = label(prediction0==0)[0] # or whatever seed method you're trying
        print "Starting watershed"
        w = skmorph.watershed(prediction0, seeds)
        seg = w
        print "Finished watershed"

        rag = None

        if json_val["perform_inclusion_removal"]:
            rag = agglo.Rag(w, prediction0, merge_priority_function=agglo.boundary_median, show_progress=True)
            print "Starting inclusion removal"
            rag.remove_inclusions()
            print "Finished inclusion removal"
            seg = rag.get_segmentation()

        if json_val["perform_median_segmentation"]:
            if rag is None:
                rag = agglo.Rag(w, prediction0, merge_priority_function=agglo.boundary_median, show_progress=True)
            rag.agglomerate(numpy.inf)
            rag_ucm = rag.get_ucm()
            imio.write_image_stack(rag_ucm, str(stackname + '.ucm.lzf.h5'), compression='lzf')
            segthres = json_val["segmentation_thresholds"]
            for val in segthres:
                rav = imio.ucm_to_raveler(rag_ucm, val, val, min_sp_size=0)
                outdir = str(json_val["output_dir"] + "/raveler-export/" + json_val["stack_name"] + "-v" + json_val["version"] + "-median-" + str(val) + "/")
                print "Writing " , outdir
                imio.write_to_raveler(*rav, directory=outdir, gray=image_stack)
        else:
            rav = imio.segs_to_raveler(w, seg, 0, do_conn_comp=False)
            outdir = str(json_val["output_dir"] + "/raveler-export/" + json_val["stack_name"] + "-v" + json_val["version"] + "/")
            print "Writing " , outdir
            imio.write_to_raveler(*rav, directory=outdir, gray=image_stack)


sys.exit(main(sys.argv))
